[global_tags]
  country_code = "${TAG_COUNTRY_CODE}"
  facility_id = "${TAG_FACILITY_ID}"
  rack_id = "${TAG_RACK_ID}"
  server_id = "${TAG_SERVER_ID}"

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "30s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log format controls the way messages are logged and can be one of "text",
  ## "structured" or, on Windows, "eventlog".
  # logformat = "text"

  ## Message key for structured logs, to override the default of "msg".
  ## Ignored if `logformat` is not "structured".
  # structured_log_message_key = "message"

  ## Name of the file to be logged to or stderr if unset or empty. This
  ## setting is ignored for the "eventlog" format.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0h"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  # hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  # omit_hostname = false

  ## Method of translating SNMP objects. Can be "netsnmp" (deprecated) which
  ## translates by calling external programs snmptranslate and snmptable,
  ## or "gosmi" which translates using the built-in gosmi library.
  # snmp_translator = "netsnmp"

  ## Name of the file to load the state of plugins from and store the state to.
  ## If uncommented and not empty, this file will be used to save the state of
  ## stateful plugins on termination of Telegraf. If the file exists on start,
  ## the state in the file will be restored for the plugins.
  # statefile = ""

  ## Flag to skip running processors after aggregators
  ## By default, processors are run a second time after aggregators. Changing
  ## this setting to true will skip the second run of processors.
  # skip_processors_after_aggregators = false

###
### CPU utilization of containers
###

# cadvisor lives here
[[inputs.prometheus]]
  urls = ["http://10.42.0.64:8080/metrics"]
  namepass = ["container_cpu_usage_seconds_total"]
  timeout = "15s"

# cadvisor seems to output duplicate metrics
[[processors.dedup]]
  namepass = ["container_cpu_usage_seconds_total"]

[[processors.starlark]]
  alias = "calculate container cpu utilization"
  namepass = ["container_cpu_usage_seconds_total"]
  script = "diff.star"
  [processors.starlark.constants]
    KEY_TAGS = ["id", "cpu"]
    CALCULATE_RATIO = true

[[processors.rename]]
  alias = "rename cadvisor metrics"
  namepass = ["container_cpu_usage_seconds_total"]
  [[processors.rename.replace]]
    measurement = "container_cpu_usage_seconds_total"
    dest = "server"

  [[processors.rename.replace]]
    field = "counter"
    dest = "cpu_busy_fraction"

##
## IPMI sensor metrics (power and fan)
##

[[inputs.ipmi_sensor]]
  sensors = ["sdr", "chassis_power_status", "dcmi_power_reading"]
  fielddrop = ["status"]
  [inputs.ipmi_sensor.tagpass]
    name = ["average_power_reading_over_sample_period", "fan*"]

[[processors.rename]]
  alias = "rename ipmi power metrics"
  namepass = ["ipmi_sensor"]
  [[processors.rename.replace]]
    measurement = "ipmi_sensor"
    dest = "server"

  [[processors.rename.replace]]
    field = "value"
    dest = "server_energy_consumption_watts"

  [processors.rename.tagpass]
    name = ["average_power_reading_over_sample_period"]

[[processors.rename]]
  alias = "rename ipmi fan metrics"
  namepass = ["ipmi_sensor"]
  [[processors.rename.replace]]
    measurement = "ipmi_sensor"
    dest = "server"

  [[processors.rename.replace]]
    field = "value"
    dest = "server_fan_speed_rpm"

  [[processors.rename.replace]]
    tag = "name"
    dest = "fan"

  [processors.rename.tagpass]
    name = ["fan*"]

##
## Network usage in bytes and packets sent
##

[[inputs.net]]
  interfaces = ["eno*"]
  fieldpass = ["bytes_sent", "bytes_recv", "packets_sent", "packets_recv"]
  [inputs.net.tagdrop]
    interface = ["all"]

[[processors.starlark]]
  alias = "calculate network rates"
  namepass = ["net"]
  script = "diff.star"
  [processors.starlark.constants]
    KEY_TAGS = ["interface"]
    CALCULATE_RATIO = false

[[processors.rename]]
  alias = "rename network metrics"
  namepass = ["net"]
  [[processors.rename.replace]]
    measurement = "net"
    dest = "server"

  [[processors.rename.replace]]
    field = "bytes_sent"
    dest = "network_transmit_bytes"

  [[processors.rename.replace]]
    field = "bytes_recv"
    dest = "network_received_bytes"

  [[processors.rename.replace]]
    field = "packets_sent"
    dest = "network_transmit_packets"

  [[processors.rename.replace]]
    field = "packets_recv"
    dest = "network_received_packets"

  [[processors.rename.replace]]
    tag = "interface"
    dest = "device"

##
## IO in bytes read/written and read/write operations
##

[[inputs.diskio]]
  devices = ["sda", "sdb"]
  fieldpass = ["reads", "writes", "read_bytes", "write_bytes"]

[[processors.starlark]]
  alias = "calculate disk io rates"
  namepass = ["diskio"]
  script = "diff.star"
  [processors.starlark.constants]
    KEY_TAGS = ["name"]
    CALCULATE_RATIO = false

[[processors.rename]]
  alias = "rename disk io metrics"
  namepass = ["diskio"]
  [[processors.rename.replace]]
    measurement = "diskio"
    dest = "server"

  [[processors.rename.replace]]
    field = "writes"
    dest = "io_writes"

  [[processors.rename.replace]]
    field = "reads"
    dest = "io_reads"

  [[processors.rename.replace]]
    field = "write_bytes"
    dest = "io_bytes_written"

  [[processors.rename.replace]]
    field = "read_bytes"
    dest = "io_bytes_read"

  [[processors.rename.replace]]
    tag = "name"
    dest = "device"

##
## CPU and DRAM power consumption
##

[[inputs.intel_powerstat]]
  fielddrop = ["thermal_design_power_watts"]

[[processors.rename]]
  alias = "rename powerstat metrics"
  namepass = ["powerstat_package"]
  [[processors.rename.replace]]
    measurement = "powerstat_package"
    dest = "server"

  [[processors.rename.replace]]
    field = "current_power_consumption_watts"
    dest = "cpu_energy_consumption_watts"

  [[processors.rename.replace]]
    field = "current_dram_power_consumption_watts"
    dest = "dram_energy_consumption_watts"

  [[processors.rename.replace]]
    tag = "package"
    dest = "cpu"

##
## Nvidia GPU metrics
##

[[inputs.nvidia_smi]]
  fieldinclude = ["power_draw", "fan_speed", "utilization_gpu"]

[[processors.scale]]
  alias = "scale gpu utilization to [0..1]"
  [[processors.scale.scaling]]
    metricpass = ["nvidia_smi"]
    factor = 0.01
    fields = ["utilization_gpu"]

[[processors.rename]]
  alias = "rename nvidia smi metrics"
  namepass = ["nvidia_smi"]
  [[processors.rename.replace]]
    measurement = "nvidia_smi"
    dest = "server"

  [[processors.rename.replace]]
    field = "power_draw"
    dest = "gpu_energy_consumption_watts"

  [[processors.rename.replace]]
    field = "fan_speed"
    dest = "gpu_fan_speed_rpm"

  [[processors.rename.replace]]
    field = "utilization_gpu"
    dest = "gpu_busy_fraction"

##
## CPU utilization
##

[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = false
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
  report_active = true
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false
  fieldinclude = ["usage_active"]

[[processors.scale]]
  alias = "scale cpu metrics to [0..1]"
  [[processors.scale.scaling]]
    metricpass = ["cpu"]
    factor = 0.01
    fields = ["usage_active"]

[[processors.rename]]
  alias = "rename cpu metrics"
  metricpass = ["cpu"]
  ## Specify one sub-table per rename operation.
  [[processors.rename.replace]]
    measurement = "cpu"
    dest = "server"

  [[processors.rename.replace]]
    field = "usage_active"
    dest = "cpu_busy_fraction"

##
## Facility metrics from Zabbix
##

[[inputs.execd]]
  alias = "nadiki facility zabbix crawler"
  command = ["python3", "-u", "nadiki-facility-zabbix-crawler.py"]
  data_format = "influx"
  signal = "SIGHUP"

##
## Electricitymap (CO2/kWh)
##

[[inputs.exec]]
  commands = ["python3 -u nadiki-facility-electricitymap-crawler.py"]
  data_format = "influx"

##
## Outputs
##

[[outputs.influxdb_v2]]
   urls = ["${OUTPUT_INFLUXDB_URL}"]
   token = "${OUTPUT_INFLUXDB_TOKEN}"
   organization = "${OUTPUT_INFLUXDB_ORGANIZATION}"
   bucket = "${TAG_FACILITY_ID}" # registrar creates a bucket for each facility

#[[outputs.file]]
#  files = ["stdout"]

